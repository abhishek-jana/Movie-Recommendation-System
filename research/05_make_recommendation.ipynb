{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\abhis\\\\Desktop\\\\MLProjects\\\\Movie-Recommendation-Sysytem'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from surprise.dataset import Trainset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RecommendationPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def create_ranked_df(self,movies, reviews):\n",
    "        '''\n",
    "        INPUT\n",
    "        movies - the movies dataframe\n",
    "        reviews - the reviews dataframe\n",
    "        \n",
    "        OUTPUT\n",
    "        ranked_movies - a dataframe with movies that are sorted by highest avg rating, more reviews, \n",
    "                        then time, and must have more than 4 ratings\n",
    "        '''\n",
    "        \n",
    "        # Pull the average ratings and number of ratings for each movie\n",
    "        C = reviews[\"rating\"].mean()\n",
    "        movie_ratings = reviews.groupby('movieId')['rating'] \n",
    "        avg_ratings = movie_ratings.mean() # R\n",
    "        num_ratings = movie_ratings.count() # v\n",
    "        m = num_ratings.quantile(0.95)\n",
    "        weighted_rating = ((avg_ratings*num_ratings)/(num_ratings+m))+((C*m)/(num_ratings+m))\n",
    "\n",
    "        rating_count_df = pd.DataFrame({'num_ratings':num_ratings,'weighted_rating': weighted_rating}).reset_index()\n",
    "\n",
    "\n",
    "        # merge with the movies dataset\n",
    "        movies.drop([\"vote_average\",\"vote_count\"], axis=1, inplace=True)\t\n",
    "        movie_recs = movies.merge(rating_count_df, on = 'movieId')\n",
    "\n",
    "        # filter out the movies that qualify for the chart\n",
    "        ratings_filtered=movie_recs[movie_recs['num_ratings']>m]\n",
    "\n",
    "\n",
    "        # sort by top avg rating and number of ratings\n",
    "        ranked_movies = ratings_filtered.sort_values(['weighted_rating', 'num_ratings'], ascending=False)\n",
    "        \n",
    "        return ranked_movies\n",
    "    \n",
    "    def popular_recs_filtered(self, n_top, years=None, genres=None):\n",
    "        '''\n",
    "        REDO THIS DOC STRING\n",
    "        \n",
    "        INPUT:\n",
    "        user_id - the user_id (str) of the individual you are making recommendations for\n",
    "        n_top - an integer of the number recommendations you want back\n",
    "        ranked_movies - a pandas dataframe of the already ranked movies based on avg rating, count, and time\n",
    "        years - a list of strings with years of movies\n",
    "        genres - a list of strings with genres of movies\n",
    "        \n",
    "        OUTPUT:\n",
    "        top_movies - a list of the n_top recommended movies by movie title in order best to worst\n",
    "        '''\n",
    "        movies_df = pd.read_csv(os.path.join(\"artifacts\",\"data_preparation\",\"final_data\",\"movies.csv\"))\n",
    "        ratings_df = pd.read_csv(os.path.join(\"artifacts\",\"data_preparation\",\"final_data\",\"ratings.csv\"))\n",
    "        unique_genres = json.load(open(os.path.join(\"artifacts\",\"data_preparation\",\"final_data\",\"unique_categories.json\"),'rb'))\n",
    "        ranked_movies = self.create_ranked_df(movies_df, ratings_df)\n",
    "        ranked_movies['year'] = ranked_movies['title'].str.extract(r'\\((\\d+)\\)').fillna(-1)\n",
    "\n",
    "\n",
    "        # Create new columns based on the number of unique genres\n",
    "        genre_columns = []\n",
    "        for genre in unique_genres:\n",
    "            genre_columns.append(ranked_movies['genres'].apply(lambda x: int(genre in x)).rename(f'{genre}'))\n",
    "\n",
    "        # Concatenate the genre columns with the movies_df DataFrame\n",
    "        df_concatenated = pd.concat([ranked_movies] + genre_columns, axis=1)\n",
    "\n",
    "        # Filter movies based on years and genres if provided\n",
    "        if years is not None and genres is not None:\n",
    "            filtered_movies = df_concatenated[(df_concatenated['year'].isin(years)) & (df_concatenated[genres].sum(axis=1) > 0)]\n",
    "        elif years is not None:\n",
    "            filtered_movies = df_concatenated[df_concatenated['year'].isin(years)]\n",
    "        elif genres is not None:\n",
    "            filtered_movies = df_concatenated[df_concatenated[genres].sum(axis=1) > 0]\n",
    "        else:\n",
    "            filtered_movies = df_concatenated.copy()\n",
    "        \n",
    "        # Sort the filtered movies by rank and select the top n_top movies\n",
    "        top_movies = filtered_movies['title'].head(n_top)\n",
    "        \n",
    "        return top_movies\n",
    "    \n",
    "    # Function that takes in movie title as input and outputs most similar movies\n",
    "    def content_recommendations(self,movie_name, n_top = 10):\n",
    "        movies_df = pd.read_csv(os.path.join(\"artifacts\",\"data_preparation\",\"final_data\",\"movies.csv\"))\n",
    "\n",
    "        cosine_sim = load_npz(os.path.join(\"artifacts\",\"content_based_model\",\"content_matrix.npz\"))\n",
    "        # cosine_sim = pd.DataFrame(cosine_sim.todense())\n",
    "\n",
    "        indices=pd.Series(data=list(movies_df.index), index= movies_df['title'] )\n",
    "        \n",
    "        # Get the index of the movie that matches the title\n",
    "        idx = indices[movie_name]\n",
    "        \n",
    "        # Get the row vector of cosine similarity scores\n",
    "        similarity_scores = cosine_sim[idx, :]\n",
    "\n",
    "        # Convert the row vector to a dense array\n",
    "        sim_scores_dense = similarity_scores.toarray()[0]\n",
    "\n",
    "        # Enumerate the similarity scores with their indices\n",
    "        sim_scores = list(enumerate(sim_scores_dense))\n",
    "\n",
    "        # Sort the movies based on the similarity scores\n",
    "        sim_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        # # Sort the movies based on the similarity scores\n",
    "        # sim_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get the scores of the 10 most similar movies\n",
    "        sim_scores=sim_scores[1: (n_top + 1)]\n",
    "        \n",
    "        # Get the movie indices\n",
    "        ind=[x[0] for x in sim_scores]\n",
    "        # for (x,y) in sim_scores:\n",
    "        #     ind.append(x)\n",
    "            \n",
    "        # Return the top 10 most similar movies\n",
    "        tit=[]\n",
    "        for x in ind:\n",
    "            tit.append(movies_df.iloc[x]['title'])\n",
    "        return pd.Series(data=tit, index=ind)\n",
    "\n",
    "    \n",
    "    def get_avg_ratings(self,movie_lists):\n",
    "        indices = pickle.load(open(os.path.join(\"artifacts\",\"collaborative_filtering_model\",\"nn_item_indices.pkl\"),'rb'))\n",
    "        # Get the index of the movie that matches the title\n",
    "        ratings = []\n",
    "        for movie in movie_lists:\n",
    "            idx = indices[movie]\n",
    "            ratings.append(np.round(np.mean(user_movie_matrix.getrow(idx).data),2))\n",
    "        return ratings\n",
    "\n",
    "    def fetch_poster_url(self,movie_lists):\n",
    "        movies_df = pd.read_csv(os.path.join(\"artifacts\",\"data_preparation\",\"final_data\",\"movies.csv\"))\n",
    "        movies_df = movies_df[['title','tmdbId','genres','poster_path']]\n",
    "        poster_path_url = 'https://image.tmdb.org/t/p/w500'\n",
    "        urls = []\n",
    "        for movie in movie_lists:\n",
    "            urls.append(poster_path_url+movies_df['poster_path'][movies_df['title'] == movie].iloc[0])\n",
    "        return urls\n",
    "    \n",
    "    def recommend_movie_neighbour(self,movie_name, n_top = 10):\n",
    "        user_movie_matrix = load_npz(os.path.join(\"artifacts\",\"collaborative_filtering_model\",\"user_movie_matrix.npz\"))\n",
    "        model = pickle.load(open(os.path.join(\"artifacts\",\"collaborative_filtering_model\",\"nearest_neighbors_movie.pkl\"),'rb'))\n",
    "        # user_movie_matrix.data[user_movie_matrix == 0] = np.nan\n",
    "        indices = pickle.load(open(os.path.join(\"artifacts\",\"collaborative_filtering_model\",\"nn_item_indices.pkl\"),'rb'))\n",
    "        # Get the index of the movie that matches the title\n",
    "        idx = indices[movie_name]\n",
    "\n",
    "        movie_list = []\n",
    "        avg_rating = []\n",
    "        # movie_id = np.where(user_movie_matrix.tocoo().row == movie_name)[0][0]\n",
    "        distance, suggestion = model.kneighbors(user_movie_matrix[idx],n_neighbors = int(n_top)+1)\n",
    "\n",
    "        poster_url = 'test' #fetch_poster(suggestion)\n",
    "\n",
    "        for movies_id in suggestion[0]:\n",
    "            movie = next(key for key, val in indices.items() if val == movies_id) # since we know the value is present\n",
    "            ratings = np.mean(user_movie_matrix.getrow(movies_id).data)\n",
    "            avg_rating.append(ratings)\n",
    "            movie_list.append(movie)\n",
    "\n",
    "        poster_url = self.fetch_poster_url(movie_list)\n",
    "\n",
    "        return pd.DataFrame({'movie':movie_list[1:], 'poster_path': poster_url[1:],'rating': avg_rating[1:]})\n",
    "    \n",
    "    def recomend_top_movie_user(self,user_id):\n",
    "        svd_model = pickle.load(open(os.path.join(\"artifacts\",\"collaborative_filtering_model\",\"svd_model.pkl\"),'rb'))\n",
    "        trainset: Trainset = svd_model.trainset\n",
    "        svd_item_indices = pickle.load(open(os.path.join(\"artifacts\",\"collaborative_filtering_model\",\"svd_item_indices.pkl\"),'rb'))\n",
    "        user_ratings = trainset.ur[user_id]  # Get the user's ratings from the trainset.ur attribute\n",
    "        watched_movies = [item_id for item_id, _ in user_ratings]  # Extract the item IDs\n",
    "        all_movies = [key for key, _ in svd_item_indices.items()]  # Get a list of all item IDs in the trainset\n",
    "        unwatched_movies = [item_id for item_id in all_movies if item_id not in watched_movies]\n",
    "        predicted_ratings = {item_id: svd_model.predict(user_id, item_id).est for item_id in unwatched_movies}\n",
    "        sorted_movies_dict = {item_id: predicted_ratings[item_id] for item_id in sorted(unwatched_movies, key=lambda x: predicted_ratings[x], reverse=True)}\n",
    "\n",
    "        return list(sorted_movies_dict.items())[:10]\n",
    "    \n",
    "    def recommend_similar_movie_user(self,user_id, movie):\n",
    "        svd_model = pickle.load(open(os.path.join(\"artifacts\",\"collaborative_filtering_model\",\"svd_model.pkl\"),'rb'))\n",
    "        trainset: Trainset = svd_model.trainset\n",
    "        svd_item_indices = pickle.load(open(os.path.join(\"artifacts\",\"collaborative_filtering_model\",\"svd_item_indices.pkl\"),'rb'))\n",
    "        user_ratings = trainset.ur[user_id]  # Get the user's ratings from the trainset.ur attribute\n",
    "        watched_movies = [item_id for item_id, _ in user_ratings]  # Extract the item IDs\n",
    "        all_movies = [key for key, _ in svd_item_indices.items()]  # Get a list of all item IDs in the trainset\n",
    "        unwatched_movies = [item_id for item_id in all_movies if item_id not in watched_movies]\n",
    "\n",
    "        # Step 3: Determine the number of similar movies to consider\n",
    "        num_similar_movies = max(len(watched_movies) * 1.5, 20)\n",
    "\n",
    "        # Step 1: Get recommendations from recommend_movie_neighbour\n",
    "        recommendations = self.recommend_movie_neighbour(movie, n_top=num_similar_movies)['movie'].to_list()\n",
    "        recommended_unwatched_movies = set(unwatched_movies) & set(recommendations)\n",
    "        # Step 6: Predict ratings for unwatched movies\n",
    "        predicted_ratings = {movie: svd_model.predict(user_id, movie).est for movie in recommended_unwatched_movies}\n",
    "        sorted_movies_dict = {movie: predicted_ratings[movie] for movie in sorted(recommended_unwatched_movies, key=lambda x: predicted_ratings[x], reverse=True)}\n",
    "        return list(sorted_movies_dict.items())[:10]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_reco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
