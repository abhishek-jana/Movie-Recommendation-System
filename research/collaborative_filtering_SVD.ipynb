{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singular Value Decomposition\n",
    "In this notebook, you will get some hands on practice with SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\abhis\\\\Desktop\\\\MLProjects\\\\Movie Recommender'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from scipy.sparse import csr_matrix\n",
    "from surprise import SVD, Reader, Dataset \n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('artifacts/data_preparation/final_data/ratings.csv')\n",
    "movies_df = pd.read_csv('artifacts/data_preparation/final_data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1      307     3.5\n",
       "1       1      481     3.5\n",
       "2       1     1091     1.5\n",
       "3       1     1257     4.5\n",
       "4       1     1449     4.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_200 = ratings_df['userId'].value_counts() > 200\n",
    "# getting the index of these users\n",
    "ind = more_than_200[more_than_200].index\n",
    "ratings_df = ratings_df[ratings_df['userId'].isin(ind)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# megre movies with ratings\n",
    "\n",
    "rating_with_movies = ratings_df.merge(movies_df, on = \"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which movie got how much rating\n",
    "\n",
    "num_rating = rating_with_movies.groupby('title')['rating'].count().reset_index()\n",
    "num_rating.rename(columns={\"rating\":\"num_of_rating\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rating = rating_with_movies.merge(num_rating, on = 'title')\n",
    "# filter out book with more than 50 ratings only\n",
    "\n",
    "final_rating =final_rating[final_rating['num_of_rating'] >= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId    35004\n",
       "title     12509\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rating[['userId','title']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rating.drop_duplicates(['userId','title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId    35004\n",
       "title     12509\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rating[['userId','title']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcLabel, vLabel = ('userId', 'movieId'), 'rating'\n",
    "rcCat = [CategoricalDtype(sorted(ratings_df[col].unique()), ordered=True) for col in rcLabel]\n",
    "rc = [ratings_df[column].astype(aType).cat.codes for column, aType in zip(rcLabel, rcCat)]\n",
    "mat = csr_matrix((ratings_df[vLabel], rc), shape=tuple(cat.categories.size for cat in rcCat))\n",
    "movie_pivot = ( pd.DataFrame.sparse.from_spmatrix(\n",
    "    mat, index=rcCat[0].categories, columns=rcCat[1].categories) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193861</th>\n",
       "      <th>193863</th>\n",
       "      <th>193864</th>\n",
       "      <th>193866</th>\n",
       "      <th>193868</th>\n",
       "      <th>193876</th>\n",
       "      <th>193878</th>\n",
       "      <th>193880</th>\n",
       "      <th>193882</th>\n",
       "      <th>193886</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283184</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283195</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283204</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283224</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35004 rows Ã— 52949 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1       2       3       4       5       6       7       8       \\\n",
       "4          4.0     4.0     0.0     0.0     2.0     4.5     0.0     0.0   \n",
       "19         0.0     0.0     4.0     0.0     0.0     4.0     0.0     0.0   \n",
       "42         4.0     3.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "43         5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "51         4.0     3.0     4.0     0.0     0.0     3.0     0.0     0.0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "283184     4.0     2.5     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "283185     0.0     0.0     0.0     4.0     0.0     0.0     3.0     0.0   \n",
       "283195     5.0     4.0     4.5     0.0     0.0     4.5     0.0     0.0   \n",
       "283204     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "283224     0.0     0.0     4.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        9       10      ...  193861  193863  193864  193866  193868  193876  \\\n",
       "4          0.0     4.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "19         4.0     4.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "42         0.0     3.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "43         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "51         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "283184     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "283185     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "283195     0.0     3.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "283204     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "283224     0.0     3.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        193878  193880  193882  193886  \n",
       "4          0.0     0.0     0.0     0.0  \n",
       "19         0.0     0.0     0.0     0.0  \n",
       "42         0.0     0.0     0.0     0.0  \n",
       "43         0.0     0.0     0.0     0.0  \n",
       "51         0.0     0.0     0.0     0.0  \n",
       "...        ...     ...     ...     ...  \n",
       "283184     0.0     0.0     0.0     0.0  \n",
       "283185     0.0     0.0     0.0     0.0  \n",
       "283195     0.0     0.0     0.0     0.0  \n",
       "283204     0.0     0.0     0.0     0.0  \n",
       "283224     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[35004 rows x 52949 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df['userId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_subset = movie_pivot[[13,  155, 855]][np.all(movie_pivot[[13,  155, 855]] != 0, axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52772     3.666667\n",
      "63810     2.333333\n",
      "101928    1.000000\n",
      "126870    2.666667\n",
      "128244    3.000000\n",
      "183233    2.333333\n",
      "201555    3.000000\n",
      "216371    3.333333\n",
      "dtype: float64\n",
      "13     2.375\n",
      "155    3.000\n",
      "855    2.625\n",
      "dtype: float64\n",
      "12    Balto (1995)\n",
      "Name: title, dtype: object\n",
      "150    Beyond Rangoon (1995)\n",
      "Name: title, dtype: object\n",
      "824    Every Other Weekend (Un week-end sur deux) (1990)\n",
      "Name: title, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user with the highest average rating\n",
    "print(user_movie_subset.mean(axis=1))\n",
    "\n",
    "# movie with highest average rating\n",
    "print(user_movie_subset.mean(axis=0))\n",
    "\n",
    "# list of movie names\n",
    "for movie_id in [13,  155, 855]:\n",
    "    print(movies_df[movies_df['movieId'] == movie_id]['title'])\n",
    "    \n",
    "# users by movies\n",
    "user_movie_subset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a little more context about the matrix we will be performing Singular Value Decomposition on, we're going to do just that. To get started, let's remind ourselves about the dimensions of each of the matrices we are going to get back. Essentially, we are going to split the **user_movie_subset** matrix into three matrices:\n",
    "$$\n",
    "U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "4. Below you can find the code used to perform SVD in numpy. You can see more about this functionality in the [documentation](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html). What do you notice about the shapes of your matrices? If you try to take the dot product of the three objects you get back, can you directly do this to get back the user-movie matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (8, 8), (3, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, vt = np.linalg.svd(user_movie_subset)\n",
    "s.shape, u.shape, vt.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dimensions of the three returned objects, we can see the following:\n",
    "\n",
    " 1. The u matrix is a square matrix with the number of rows and columns equaling the number of users. \n",
    "\n",
    " 2. The v transpose matrix is also a square matrix with the number of rows and columns equaling the number of items.\n",
    "\n",
    " 3. The sigma matrix is actually returned as just an array with 3 values.  \n",
    "\n",
    " In order to set up the matrices in a way that they can be multiplied together, we have a few steps to perform: \n",
    "\n",
    " 1. Turn sigma into a square matrix with the number of latent features we would like to keep. \n",
    "\n",
    " 2. Change the columns of u and the rows of v transpose to match this number of dimensions. \n",
    "\n",
    " If we would like to exactly re-create the user-movie matrix, we could choose to keep all of the latent features.\n",
    "\n",
    " 5. Use the thoughts from the above question to create u, s, and vt with four latent features. When you have all three matrices created correctly, run the test below to show that the dot product of the three matrices creates the original user-movie matrix. The matrices should have the following dimensions:\n",
    "\n",
    "$$\n",
    "U_{nxk} \\\\ \\Sigma_{kxk} \\\\ V^T_{kxm}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- n is the number of users\n",
    "- k is the number of latent features to keep (3 for this case)\n",
    "- m is the number of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dimensions of u, s, and vt as necessary to use three latent features\n",
    "# update the shape of u and store in u_new\n",
    "u_new = u[:, :len(s)]\n",
    "\n",
    "# update the shape of s and store in s_new\n",
    "s_new = np.zeros((len(s), len(s)))\n",
    "s_new[:len(s), :len(s)] = np.diag(s) \n",
    "\n",
    "# Because we are using 3 latent features and there are only 3 movies, \n",
    "# vt and vt_new are the same\n",
    "vt_new = vt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the sigma matrix can actually tell us how much of the original variability in the user-movie matrix is captured by each latent feature. The total amount of variability to be explained is the sum of the squared diagonal elements. The amount of variability explained by the first componenet is the square of the first value in the diagonal. The amount of variability explained by the second componenet is the square of the second value in the diagonal.\n",
    "\n",
    "6. Using the above information, can you determine the amount of variability in the original user-movie matrix that can be explained by only using the first two components? Use the cell below for your work, and then test your answer against the solution with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total variance in the original matrix is 193.99999999999997.\n",
      "Ther percentage of variability captured by the first two components is 99.1%.\n"
     ]
    }
   ],
   "source": [
    "total_var = np.sum(s**2)\n",
    "var_exp_comp1_and_comp2 = s[0]**2 + s[1]**2\n",
    "perc_exp = round(var_exp_comp1_and_comp2/total_var*100, 2)\n",
    "print(\"The total variance in the original matrix is {}.\".format(total_var))\n",
    "print(\"Ther percentage of variability captured by the first two components is {}%.\".format(perc_exp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Similar to in the previous question, change the shapes of your u, sigma, and v transpose matrices. However, this time consider only using the first 2 components to reproduce the user-movie matrix instead of all 3. After you have your matrices set up, check your matrices against the solution by running the tests. The matrices should have the following dimensions:\n",
    "\n",
    "$$\n",
    "U_{nxk} \\\\ \\Sigma_{kxk} \\\\ V^T_{kxm}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- n is the number of users\n",
    "- k is the number of latent features to keep (2 for this case)\n",
    "- m is the number of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dimensions of u, s, and vt as necessary to use four latent features\n",
    "# update the shape of u and store in u_new\n",
    "k = 2\n",
    "u_2 = u[:, :k]\n",
    "\n",
    "# update the shape of s and store in s_new\n",
    "s_2 = np.zeros((k, k))\n",
    "s_2[:k, :k] = np.diag(s[:k]) \n",
    "\n",
    "# Because we are using 2 latent features, we need to update vt this time\n",
    "vt_2 = vt[:k, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is now that we don't have all of the latent features, how well can we really re-create the original user-movie matrix?\n",
    "\n",
    "8. When using all 3 latent features, we saw that we could exactly reproduce the user-movie matrix. Now that we only have 2 latent features, we might measure how well we are able to reproduce the original matrix by looking at the sum of squared errors from each rating produced by taking the dot product as compared to the actual rating. Find the sum of squared error based on only the two latent features, and use the following cell to test against the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2), (8, 2), (2, 3))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_2.shape, u_2.shape, vt_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the dot product\n",
    "pred_ratings = np.dot(np.dot(u_2, s_2), vt_2)\n",
    "\n",
    "# Compute the squared error for each predicted vs. actual rating\n",
    "sum_square_errs = np.sum(np.sum((user_movie_subset - pred_ratings)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.74988951, 3.7278407 , 3.54998859],\n",
       "        [1.33228046, 3.36157307, 2.26932108],\n",
       "        [1.01578809, 1.01717991, 0.96528226],\n",
       "        [3.20238095, 2.2202221 , 2.55496784],\n",
       "        [3.04736427, 3.05153973, 2.89584679],\n",
       "        [1.87655951, 2.86567746, 2.27144347],\n",
       "        [3.04736427, 3.05153973, 2.89584679],\n",
       "        [1.87978903, 4.86919167, 3.26434183]]),\n",
       "         13   155  855\n",
       " 52772   4.0  4.0  3.0\n",
       " 63810   1.0  3.0  3.0\n",
       " 101928  1.0  1.0  1.0\n",
       " 126870  3.0  2.0  3.0\n",
       " 128244  3.0  3.0  3.0\n",
       " 183233  2.0  3.0  2.0\n",
       " 201555  3.0  3.0  3.0\n",
       " 216371  2.0  5.0  3.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ratings, user_movie_subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you may be thinking... why would we want to choose a k that doesn't just give us back the full user-movie matrix with all the original ratings. This is a good question. One reason might be for computational reasons - sure, you may want to reduce the dimensionality of the data you are keeping, but really this isn't the main reason we would want to perform reduce k to lesser than the minimum of the number of movies or users.\n",
    "\n",
    "Let's take a step back for a second. In this example we just went through, your matrix was very clean. That is, for every user-movie combination, we had a rating. There were no missing values. But what we know from the previous lesson is that the user-movie matrix is full of missing values.\n",
    "\n",
    "Therefore, if we keep all k latent features it is likely that latent features with smaller values in the sigma matrix will explain variability that is probably due to noise and not signal. Furthermore, if we use these \"noisey\" latent features to assist in re-constructing the original user-movie matrix it will potentially (and likely) lead to worse ratings than if we only have latent features associated with signal.\n",
    "\n",
    "9. Let's try introducing just a little of the real world into this example by performing SVD on a matrix with missing values. Below I have added a new user to our matrix who hasn't rated all three of our movies. Try performing SVD on the new matrix. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SparseArray does not support item assignment via setitem",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# This line adds one nan value as the very first entry in our matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m user_movie_subset\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m      4\u001b[0m \u001b[39m# Try svd with this new matrix\u001b[39;00m\n\u001b[0;32m      5\u001b[0m u, s, vt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39msvd(user_movie_subset)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 849\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\indexing.py:1835\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1832\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1834\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1835\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1836\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1837\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\indexing.py:1928\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1925\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1926\u001b[0m     \u001b[39m# scalar value\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m     \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m ilocs:\n\u001b[1;32m-> 1928\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_single_column(loc, value, pi)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\indexing.py:2034\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   2030\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39misetitem(loc, value)\n\u001b[0;32m   2031\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2032\u001b[0m     \u001b[39m# set value into the column (first attempting to operate inplace, then\u001b[39;00m\n\u001b[0;32m   2033\u001b[0m     \u001b[39m#  falling back to casting if necessary)\u001b[39;00m\n\u001b[1;32m-> 2034\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mcolumn_setitem(loc, plane_indexer, value)\n\u001b[0;32m   2036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1384\u001b[0m, in \u001b[0;36mBlockManager.column_setitem\u001b[1;34m(self, loc, idx, value, inplace_only)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     col_mgr\u001b[39m.\u001b[39msetitem_inplace(idx, value)\n\u001b[0;32m   1383\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1384\u001b[0m     new_mgr \u001b[39m=\u001b[39m col_mgr\u001b[39m.\u001b[39;49msetitem((idx,), value)\n\u001b[0;32m   1385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miset(loc, new_mgr\u001b[39m.\u001b[39m_block\u001b[39m.\u001b[39mvalues, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\internals\\managers.py:394\u001b[0m, in \u001b[0;36mBaseBlockManager.setitem\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_no_reference(\u001b[39m0\u001b[39m):\n\u001b[0;32m    390\u001b[0m     \u001b[39m# if being referenced -> perform Copy-on-Write and clear the reference\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[39m# this method is only called if there is a single block -> hardcoded 0\u001b[39;00m\n\u001b[0;32m    392\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m--> 394\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39msetitem\u001b[39;49m\u001b[39m\"\u001b[39;49m, indexer\u001b[39m=\u001b[39;49mindexer, value\u001b[39m=\u001b[39;49mvalue)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1622\u001b[0m, in \u001b[0;36mEABackedBlock.setitem\u001b[1;34m(self, indexer, value, using_cow)\u001b[0m\n\u001b[0;32m   1619\u001b[0m check_setitem_lengths(indexer, value, values)\n\u001b[0;32m   1621\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1622\u001b[0m     values[indexer] \u001b[39m=\u001b[39m value\n\u001b[0;32m   1623\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1624\u001b[0m     _catch_deprecated_value_error(err)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movies\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py:586\u001b[0m, in \u001b[0;36mSparseArray.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, value):\n\u001b[0;32m    582\u001b[0m     \u001b[39m# I suppose we could allow setting of non-fill_value elements.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     \u001b[39m# TODO(SparseArray.__setitem__): remove special cases in\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     \u001b[39m# ExtensionBlock.where\u001b[39;00m\n\u001b[0;32m    585\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSparseArray does not support item assignment via setitem\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 586\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mTypeError\u001b[0m: SparseArray does not support item assignment via setitem"
     ]
    }
   ],
   "source": [
    "# This line adds one nan value as the very first entry in our matrix\n",
    "user_movie_subset.iloc[0, 0] = np.nan\n",
    "\n",
    "# Try svd with this new matrix\n",
    "u, s, vt = np.linalg.svd(user_movie_subset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with just one nan value we cannot perform SVD! This is going to be a huge problem, because our real dataset has nan values everywhere! This is where FunkSVD comes in to help."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing FunkSVD\n",
    "\n",
    "1. You will use the user_movie_subset matrix to show that your FunkSVD algorithm will converge. In the below cell, use the comments and document string to assist you as you complete writing your own function to complete FunkSVD. You may also want to try to complete the funtion on your own without the assistance of comments. You may feel free to remove and add to the function in any way that gets you a working solution!\n",
    "\n",
    "Notice: There isn't a sigma matrix in this version of matrix factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_mat = np.matrix(user_movie_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunkSVD(ratings_mat, latent_features=4, learning_rate=0.0001, iters=100):\n",
    "    '''\n",
    "    This function performs matrix factorization using a basic form of FunkSVD with no regularization\n",
    "    \n",
    "    INPUT:\n",
    "    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values\n",
    "    latent_features - (int) the number of latent features used\n",
    "    learning_rate - (float) the learning rate \n",
    "    iters - (int) the number of iterations\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_mat - (numpy array) a user by latent feature matrix\n",
    "    movie_mat - (numpy array) a latent feature by movie matrix\n",
    "    '''\n",
    "    \n",
    "    # Set up useful values to be used through the rest of the function\n",
    "    n_users = ratings_mat.shape[0]\n",
    "    n_movies = ratings_mat.shape[1]\n",
    "    num_ratings = np.count_nonzero(~np.isnan(ratings_mat))\n",
    "    \n",
    "    # initialize the user and movie matrices with random values\n",
    "    user_mat = np.random.rand(n_users, latent_features)\n",
    "    movie_mat = np.random.rand(latent_features, n_movies)\n",
    "    \n",
    "    # initialize sse at 0 for first iteration\n",
    "    sse_accum = 0\n",
    "    \n",
    "    # keep track of iteration and MSE\n",
    "    print(\"Optimizaiton Statistics\")\n",
    "    print(\"Iterations | Mean Squared Error \")\n",
    "    \n",
    "    # for each iteration\n",
    "    for iteration in range(iters):\n",
    "\n",
    "        # update our sse\n",
    "        old_sse = sse_accum\n",
    "        sse_accum = 0\n",
    "        \n",
    "        # For each user-movie pair\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_movies):\n",
    "                \n",
    "                # if the rating exists\n",
    "                if ratings_mat[i, j] > 0:\n",
    "                    \n",
    "                    # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                    diff = ratings_mat[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "                    \n",
    "                    # Keep track of the sum of squared errors for the matrix\n",
    "                    sse_accum += diff**2\n",
    "                    \n",
    "                    # update the values in each matrix in the direction of the gradient\n",
    "                    for k in range(latent_features):\n",
    "                        user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                        movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "\n",
    "        # print results\n",
    "        print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / num_ratings))\n",
    "        \n",
    "    return user_mat, movie_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 2.596023\n",
      "2 \t\t 0.606464\n",
      "3 \t\t 0.495485\n",
      "4 \t\t 0.397009\n",
      "5 \t\t 0.300170\n",
      "6 \t\t 0.231268\n",
      "7 \t\t 0.193369\n",
      "8 \t\t 0.174199\n",
      "9 \t\t 0.162853\n",
      "10 \t\t 0.154003\n"
     ]
    }
   ],
   "source": [
    "user_mat, movie_mat = FunkSVD(ratings_mat, \n",
    "                              latent_features=3, \n",
    "                              learning_rate=0.05, \n",
    "                              iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.75970223 3.53204469 3.37950272]\n",
      " [1.47838469 3.60052284 2.5170406 ]\n",
      " [1.00899746 1.05385648 0.9636682 ]\n",
      " [3.30721258 2.474125   2.65998433]\n",
      " [3.0003963  2.93900709 2.95777222]\n",
      " [1.78147728 2.81359643 2.0772378 ]\n",
      " [3.03125546 3.0867048  2.9090706 ]\n",
      " [1.88539646 4.81076812 3.0571695 ]]\n",
      "[[4. 4. 3.]\n",
      " [1. 3. 3.]\n",
      " [1. 1. 1.]\n",
      " [3. 2. 3.]\n",
      " [3. 3. 3.]\n",
      " [2. 3. 2.]\n",
      " [3. 3. 3.]\n",
      " [2. 5. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(user_mat, movie_mat))\n",
    "print(ratings_mat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The predicted ratings from the dot product are already starting to look a lot like the original data values even after only 10 iterations. Clearly the model is not done learning, but things are looking good.**\n",
    "\n",
    "3. Let's try out the function again on the user_movie_subset dataset. This time we will again use 3 latent features and a learning rate of 0.005. However, let's bump up the number of iterations to 300. When you take the dot product of the resulting U and V matrices, how does the resulting user_movie matrix compare to the original subset of the data? What do you notice about the mean squared error at the end of each training iteration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 4.432049\n",
      "2 \t\t 3.804166\n",
      "3 \t\t 3.189154\n",
      "4 \t\t 2.612832\n",
      "5 \t\t 2.097802\n",
      "6 \t\t 1.659277\n",
      "7 \t\t 1.303033\n",
      "8 \t\t 1.025953\n",
      "9 \t\t 0.818530\n",
      "10 \t\t 0.668078\n",
      "11 \t\t 0.561527\n",
      "12 \t\t 0.487239\n",
      "13 \t\t 0.435811\n",
      "14 \t\t 0.400156\n",
      "15 \t\t 0.375192\n",
      "16 \t\t 0.357407\n",
      "17 \t\t 0.344427\n",
      "18 \t\t 0.334673\n",
      "19 \t\t 0.327102\n",
      "20 \t\t 0.321023\n",
      "21 \t\t 0.315977\n",
      "22 \t\t 0.311654\n",
      "23 \t\t 0.307845\n",
      "24 \t\t 0.304403\n",
      "25 \t\t 0.301225\n",
      "26 \t\t 0.298238\n",
      "27 \t\t 0.295387\n",
      "28 \t\t 0.292633\n",
      "29 \t\t 0.289945\n",
      "30 \t\t 0.287300\n",
      "31 \t\t 0.284680\n",
      "32 \t\t 0.282073\n",
      "33 \t\t 0.279466\n",
      "34 \t\t 0.276853\n",
      "35 \t\t 0.274225\n",
      "36 \t\t 0.271577\n",
      "37 \t\t 0.268906\n",
      "38 \t\t 0.266208\n",
      "39 \t\t 0.263480\n",
      "40 \t\t 0.260721\n",
      "41 \t\t 0.257928\n",
      "42 \t\t 0.255101\n",
      "43 \t\t 0.252240\n",
      "44 \t\t 0.249343\n",
      "45 \t\t 0.246412\n",
      "46 \t\t 0.243445\n",
      "47 \t\t 0.240444\n",
      "48 \t\t 0.237410\n",
      "49 \t\t 0.234343\n",
      "50 \t\t 0.231244\n",
      "51 \t\t 0.228117\n",
      "52 \t\t 0.224960\n",
      "53 \t\t 0.221778\n",
      "54 \t\t 0.218572\n",
      "55 \t\t 0.215343\n",
      "56 \t\t 0.212095\n",
      "57 \t\t 0.208830\n",
      "58 \t\t 0.205550\n",
      "59 \t\t 0.202259\n",
      "60 \t\t 0.198959\n",
      "61 \t\t 0.195654\n",
      "62 \t\t 0.192346\n",
      "63 \t\t 0.189039\n",
      "64 \t\t 0.185736\n",
      "65 \t\t 0.182440\n",
      "66 \t\t 0.179155\n",
      "67 \t\t 0.175884\n",
      "68 \t\t 0.172630\n",
      "69 \t\t 0.169397\n",
      "70 \t\t 0.166189\n",
      "71 \t\t 0.163007\n",
      "72 \t\t 0.159856\n",
      "73 \t\t 0.156738\n",
      "74 \t\t 0.153656\n",
      "75 \t\t 0.150614\n",
      "76 \t\t 0.147613\n",
      "77 \t\t 0.144657\n",
      "78 \t\t 0.141748\n",
      "79 \t\t 0.138887\n",
      "80 \t\t 0.136078\n",
      "81 \t\t 0.133321\n",
      "82 \t\t 0.130620\n",
      "83 \t\t 0.127974\n",
      "84 \t\t 0.125385\n",
      "85 \t\t 0.122855\n",
      "86 \t\t 0.120384\n",
      "87 \t\t 0.117972\n",
      "88 \t\t 0.115622\n",
      "89 \t\t 0.113332\n",
      "90 \t\t 0.111103\n",
      "91 \t\t 0.108935\n",
      "92 \t\t 0.106827\n",
      "93 \t\t 0.104780\n",
      "94 \t\t 0.102792\n",
      "95 \t\t 0.100864\n",
      "96 \t\t 0.098993\n",
      "97 \t\t 0.097181\n",
      "98 \t\t 0.095424\n",
      "99 \t\t 0.093723\n",
      "100 \t\t 0.092077\n",
      "101 \t\t 0.090483\n",
      "102 \t\t 0.088940\n",
      "103 \t\t 0.087448\n",
      "104 \t\t 0.086005\n",
      "105 \t\t 0.084608\n",
      "106 \t\t 0.083258\n",
      "107 \t\t 0.081952\n",
      "108 \t\t 0.080689\n",
      "109 \t\t 0.079466\n",
      "110 \t\t 0.078284\n",
      "111 \t\t 0.077139\n",
      "112 \t\t 0.076032\n",
      "113 \t\t 0.074959\n",
      "114 \t\t 0.073920\n",
      "115 \t\t 0.072914\n",
      "116 \t\t 0.071938\n",
      "117 \t\t 0.070992\n",
      "118 \t\t 0.070074\n",
      "119 \t\t 0.069182\n",
      "120 \t\t 0.068317\n",
      "121 \t\t 0.067475\n",
      "122 \t\t 0.066657\n",
      "123 \t\t 0.065861\n",
      "124 \t\t 0.065086\n",
      "125 \t\t 0.064330\n",
      "126 \t\t 0.063594\n",
      "127 \t\t 0.062875\n",
      "128 \t\t 0.062173\n",
      "129 \t\t 0.061488\n",
      "130 \t\t 0.060817\n",
      "131 \t\t 0.060161\n",
      "132 \t\t 0.059519\n",
      "133 \t\t 0.058890\n",
      "134 \t\t 0.058272\n",
      "135 \t\t 0.057667\n",
      "136 \t\t 0.057072\n",
      "137 \t\t 0.056488\n",
      "138 \t\t 0.055914\n",
      "139 \t\t 0.055348\n",
      "140 \t\t 0.054792\n",
      "141 \t\t 0.054244\n",
      "142 \t\t 0.053704\n",
      "143 \t\t 0.053171\n",
      "144 \t\t 0.052646\n",
      "145 \t\t 0.052127\n",
      "146 \t\t 0.051614\n",
      "147 \t\t 0.051107\n",
      "148 \t\t 0.050606\n",
      "149 \t\t 0.050111\n",
      "150 \t\t 0.049621\n",
      "151 \t\t 0.049135\n",
      "152 \t\t 0.048655\n",
      "153 \t\t 0.048178\n",
      "154 \t\t 0.047706\n",
      "155 \t\t 0.047238\n",
      "156 \t\t 0.046774\n",
      "157 \t\t 0.046314\n",
      "158 \t\t 0.045857\n",
      "159 \t\t 0.045404\n",
      "160 \t\t 0.044954\n",
      "161 \t\t 0.044507\n",
      "162 \t\t 0.044063\n",
      "163 \t\t 0.043622\n",
      "164 \t\t 0.043185\n",
      "165 \t\t 0.042749\n",
      "166 \t\t 0.042317\n",
      "167 \t\t 0.041887\n",
      "168 \t\t 0.041460\n",
      "169 \t\t 0.041036\n",
      "170 \t\t 0.040613\n",
      "171 \t\t 0.040194\n",
      "172 \t\t 0.039776\n",
      "173 \t\t 0.039361\n",
      "174 \t\t 0.038949\n",
      "175 \t\t 0.038538\n",
      "176 \t\t 0.038130\n",
      "177 \t\t 0.037725\n",
      "178 \t\t 0.037321\n",
      "179 \t\t 0.036920\n",
      "180 \t\t 0.036521\n",
      "181 \t\t 0.036124\n",
      "182 \t\t 0.035729\n",
      "183 \t\t 0.035337\n",
      "184 \t\t 0.034946\n",
      "185 \t\t 0.034558\n",
      "186 \t\t 0.034172\n",
      "187 \t\t 0.033789\n",
      "188 \t\t 0.033408\n",
      "189 \t\t 0.033028\n",
      "190 \t\t 0.032652\n",
      "191 \t\t 0.032277\n",
      "192 \t\t 0.031905\n",
      "193 \t\t 0.031535\n",
      "194 \t\t 0.031167\n",
      "195 \t\t 0.030802\n",
      "196 \t\t 0.030439\n",
      "197 \t\t 0.030078\n",
      "198 \t\t 0.029720\n",
      "199 \t\t 0.029364\n",
      "200 \t\t 0.029010\n",
      "201 \t\t 0.028659\n",
      "202 \t\t 0.028311\n",
      "203 \t\t 0.027965\n",
      "204 \t\t 0.027621\n",
      "205 \t\t 0.027280\n",
      "206 \t\t 0.026941\n",
      "207 \t\t 0.026605\n",
      "208 \t\t 0.026271\n",
      "209 \t\t 0.025940\n",
      "210 \t\t 0.025612\n",
      "211 \t\t 0.025286\n",
      "212 \t\t 0.024963\n",
      "213 \t\t 0.024642\n",
      "214 \t\t 0.024324\n",
      "215 \t\t 0.024009\n",
      "216 \t\t 0.023696\n",
      "217 \t\t 0.023386\n",
      "218 \t\t 0.023079\n",
      "219 \t\t 0.022775\n",
      "220 \t\t 0.022473\n",
      "221 \t\t 0.022174\n",
      "222 \t\t 0.021877\n",
      "223 \t\t 0.021583\n",
      "224 \t\t 0.021292\n",
      "225 \t\t 0.021004\n",
      "226 \t\t 0.020719\n",
      "227 \t\t 0.020436\n",
      "228 \t\t 0.020156\n",
      "229 \t\t 0.019879\n",
      "230 \t\t 0.019604\n",
      "231 \t\t 0.019333\n",
      "232 \t\t 0.019064\n",
      "233 \t\t 0.018798\n",
      "234 \t\t 0.018534\n",
      "235 \t\t 0.018274\n",
      "236 \t\t 0.018016\n",
      "237 \t\t 0.017761\n",
      "238 \t\t 0.017508\n",
      "239 \t\t 0.017259\n",
      "240 \t\t 0.017012\n",
      "241 \t\t 0.016768\n",
      "242 \t\t 0.016526\n",
      "243 \t\t 0.016288\n",
      "244 \t\t 0.016052\n",
      "245 \t\t 0.015818\n",
      "246 \t\t 0.015588\n",
      "247 \t\t 0.015360\n",
      "248 \t\t 0.015135\n",
      "249 \t\t 0.014912\n",
      "250 \t\t 0.014692\n",
      "251 \t\t 0.014475\n",
      "252 \t\t 0.014261\n",
      "253 \t\t 0.014049\n",
      "254 \t\t 0.013839\n",
      "255 \t\t 0.013632\n",
      "256 \t\t 0.013428\n",
      "257 \t\t 0.013227\n",
      "258 \t\t 0.013027\n",
      "259 \t\t 0.012831\n",
      "260 \t\t 0.012637\n",
      "261 \t\t 0.012445\n",
      "262 \t\t 0.012256\n",
      "263 \t\t 0.012069\n",
      "264 \t\t 0.011885\n",
      "265 \t\t 0.011703\n",
      "266 \t\t 0.011524\n",
      "267 \t\t 0.011347\n",
      "268 \t\t 0.011172\n",
      "269 \t\t 0.011000\n",
      "270 \t\t 0.010830\n",
      "271 \t\t 0.010662\n",
      "272 \t\t 0.010496\n",
      "273 \t\t 0.010333\n",
      "274 \t\t 0.010172\n",
      "275 \t\t 0.010014\n",
      "276 \t\t 0.009857\n",
      "277 \t\t 0.009703\n",
      "278 \t\t 0.009550\n",
      "279 \t\t 0.009400\n",
      "280 \t\t 0.009252\n",
      "281 \t\t 0.009107\n",
      "282 \t\t 0.008963\n",
      "283 \t\t 0.008821\n",
      "284 \t\t 0.008681\n",
      "285 \t\t 0.008544\n",
      "286 \t\t 0.008408\n",
      "287 \t\t 0.008274\n",
      "288 \t\t 0.008142\n",
      "289 \t\t 0.008012\n",
      "290 \t\t 0.007884\n",
      "291 \t\t 0.007758\n",
      "292 \t\t 0.007634\n",
      "293 \t\t 0.007512\n",
      "294 \t\t 0.007391\n",
      "295 \t\t 0.007272\n",
      "296 \t\t 0.007155\n",
      "297 \t\t 0.007040\n",
      "298 \t\t 0.006926\n",
      "299 \t\t 0.006814\n",
      "300 \t\t 0.006704\n"
     ]
    }
   ],
   "source": [
    "user_mat, movie_mat = FunkSVD(ratings_mat, \n",
    "                              latent_features=3, \n",
    "                              learning_rate=0.005, \n",
    "                              iters=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.89025207 3.86684729 3.24419733]\n",
      " [0.98879293 2.98619465 3.0259511 ]\n",
      " [0.96191579 0.95822486 1.08019867]\n",
      " [3.02263668 2.02688292 2.95079038]\n",
      " [3.05188087 3.06023541 2.88775409]\n",
      " [2.00030295 2.99813973 2.00202972]\n",
      " [3.05395481 3.06909669 2.87583806]\n",
      " [2.01611003 5.02026574 2.96339174]]\n",
      "[[4. 4. 3.]\n",
      " [1. 3. 3.]\n",
      " [1. 1. 1.]\n",
      " [3. 2. 3.]\n",
      " [3. 3. 3.]\n",
      " [2. 3. 2.]\n",
      " [3. 3. 3.]\n",
      " [2. 5. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(user_mat, movie_mat))\n",
    "print(ratings_mat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this case, we were able to completely reconstruct the item-movie matrix to closer to 0 mean squared error at the end of 300th iterations.**\n",
    "\n",
    "The last time we placed an np.nan value into this matrix the entire svd algorithm in python broke. Let's see if that is still the case using your FunkSVD function. In the below cell, I have placed a nan into the first cell of your numpy array.\n",
    "\n",
    "4. Use 3 latent features, a learning rate of 0.005, and 450 iterations. Are you able to run your SVD without it breaking (something that was not true about the python built in)? Do you get a prediction for the nan value? What is your prediction for the missing value? Use the cells below to answer these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[nan,  4.,  3.],\n",
       "        [ 1.,  3.,  3.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 3.,  2.,  3.],\n",
       "        [ 3.,  3.,  3.],\n",
       "        [ 2.,  3.,  2.],\n",
       "        [ 3.,  3.,  3.],\n",
       "        [ 2.,  5.,  3.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_mat[0, 0] = np.nan\n",
    "ratings_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 3.551159\n",
      "2 \t\t 3.033426\n",
      "3 \t\t 2.547944\n",
      "4 \t\t 2.109363\n",
      "5 \t\t 1.727487\n",
      "6 \t\t 1.406337\n",
      "7 \t\t 1.144544\n",
      "8 \t\t 0.936695\n",
      "9 \t\t 0.775076\n",
      "10 \t\t 0.651262\n",
      "11 \t\t 0.557254\n",
      "12 \t\t 0.486121\n",
      "13 \t\t 0.432218\n",
      "14 \t\t 0.391145\n",
      "15 \t\t 0.359574\n",
      "16 \t\t 0.335037\n",
      "17 \t\t 0.315721\n",
      "18 \t\t 0.300302\n",
      "19 \t\t 0.287809\n",
      "20 \t\t 0.277531\n",
      "21 \t\t 0.268939\n",
      "22 \t\t 0.261639\n",
      "23 \t\t 0.255333\n",
      "24 \t\t 0.249796\n",
      "25 \t\t 0.244854\n",
      "26 \t\t 0.240375\n",
      "27 \t\t 0.236253\n",
      "28 \t\t 0.232407\n",
      "29 \t\t 0.228774\n",
      "30 \t\t 0.225303\n",
      "31 \t\t 0.221955\n",
      "32 \t\t 0.218699\n",
      "33 \t\t 0.215508\n",
      "34 \t\t 0.212364\n",
      "35 \t\t 0.209251\n",
      "36 \t\t 0.206157\n",
      "37 \t\t 0.203072\n",
      "38 \t\t 0.199989\n",
      "39 \t\t 0.196903\n",
      "40 \t\t 0.193809\n",
      "41 \t\t 0.190704\n",
      "42 \t\t 0.187587\n",
      "43 \t\t 0.184456\n",
      "44 \t\t 0.181312\n",
      "45 \t\t 0.178153\n",
      "46 \t\t 0.174982\n",
      "47 \t\t 0.171799\n",
      "48 \t\t 0.168605\n",
      "49 \t\t 0.165402\n",
      "50 \t\t 0.162193\n",
      "51 \t\t 0.158979\n",
      "52 \t\t 0.155763\n",
      "53 \t\t 0.152547\n",
      "54 \t\t 0.149335\n",
      "55 \t\t 0.146128\n",
      "56 \t\t 0.142930\n",
      "57 \t\t 0.139744\n",
      "58 \t\t 0.136573\n",
      "59 \t\t 0.133420\n",
      "60 \t\t 0.130287\n",
      "61 \t\t 0.127177\n",
      "62 \t\t 0.124094\n",
      "63 \t\t 0.121041\n",
      "64 \t\t 0.118019\n",
      "65 \t\t 0.115032\n",
      "66 \t\t 0.112082\n",
      "67 \t\t 0.109172\n",
      "68 \t\t 0.106304\n",
      "69 \t\t 0.103480\n",
      "70 \t\t 0.100703\n",
      "71 \t\t 0.097974\n",
      "72 \t\t 0.095295\n",
      "73 \t\t 0.092667\n",
      "74 \t\t 0.090093\n",
      "75 \t\t 0.087572\n",
      "76 \t\t 0.085107\n",
      "77 \t\t 0.082699\n",
      "78 \t\t 0.080347\n",
      "79 \t\t 0.078053\n",
      "80 \t\t 0.075817\n",
      "81 \t\t 0.073640\n",
      "82 \t\t 0.071521\n",
      "83 \t\t 0.069460\n",
      "84 \t\t 0.067458\n",
      "85 \t\t 0.065514\n",
      "86 \t\t 0.063627\n",
      "87 \t\t 0.061797\n",
      "88 \t\t 0.060024\n",
      "89 \t\t 0.058306\n",
      "90 \t\t 0.056643\n",
      "91 \t\t 0.055034\n",
      "92 \t\t 0.053477\n",
      "93 \t\t 0.051973\n",
      "94 \t\t 0.050518\n",
      "95 \t\t 0.049114\n",
      "96 \t\t 0.047757\n",
      "97 \t\t 0.046448\n",
      "98 \t\t 0.045184\n",
      "99 \t\t 0.043964\n",
      "100 \t\t 0.042788\n",
      "101 \t\t 0.041653\n",
      "102 \t\t 0.040558\n",
      "103 \t\t 0.039502\n",
      "104 \t\t 0.038484\n",
      "105 \t\t 0.037502\n",
      "106 \t\t 0.036556\n",
      "107 \t\t 0.035643\n",
      "108 \t\t 0.034762\n",
      "109 \t\t 0.033913\n",
      "110 \t\t 0.033094\n",
      "111 \t\t 0.032303\n",
      "112 \t\t 0.031540\n",
      "113 \t\t 0.030804\n",
      "114 \t\t 0.030093\n",
      "115 \t\t 0.029407\n",
      "116 \t\t 0.028744\n",
      "117 \t\t 0.028104\n",
      "118 \t\t 0.027484\n",
      "119 \t\t 0.026886\n",
      "120 \t\t 0.026307\n",
      "121 \t\t 0.025747\n",
      "122 \t\t 0.025205\n",
      "123 \t\t 0.024680\n",
      "124 \t\t 0.024171\n",
      "125 \t\t 0.023679\n",
      "126 \t\t 0.023201\n",
      "127 \t\t 0.022738\n",
      "128 \t\t 0.022288\n",
      "129 \t\t 0.021852\n",
      "130 \t\t 0.021428\n",
      "131 \t\t 0.021017\n",
      "132 \t\t 0.020617\n",
      "133 \t\t 0.020228\n",
      "134 \t\t 0.019849\n",
      "135 \t\t 0.019481\n",
      "136 \t\t 0.019123\n",
      "137 \t\t 0.018774\n",
      "138 \t\t 0.018433\n",
      "139 \t\t 0.018102\n",
      "140 \t\t 0.017778\n",
      "141 \t\t 0.017463\n",
      "142 \t\t 0.017155\n",
      "143 \t\t 0.016854\n",
      "144 \t\t 0.016561\n",
      "145 \t\t 0.016274\n",
      "146 \t\t 0.015993\n",
      "147 \t\t 0.015719\n",
      "148 \t\t 0.015451\n",
      "149 \t\t 0.015189\n",
      "150 \t\t 0.014932\n",
      "151 \t\t 0.014681\n",
      "152 \t\t 0.014435\n",
      "153 \t\t 0.014194\n",
      "154 \t\t 0.013958\n",
      "155 \t\t 0.013727\n",
      "156 \t\t 0.013500\n",
      "157 \t\t 0.013278\n",
      "158 \t\t 0.013060\n",
      "159 \t\t 0.012846\n",
      "160 \t\t 0.012636\n",
      "161 \t\t 0.012430\n",
      "162 \t\t 0.012228\n",
      "163 \t\t 0.012029\n",
      "164 \t\t 0.011834\n",
      "165 \t\t 0.011643\n",
      "166 \t\t 0.011455\n",
      "167 \t\t 0.011270\n",
      "168 \t\t 0.011089\n",
      "169 \t\t 0.010911\n",
      "170 \t\t 0.010736\n",
      "171 \t\t 0.010564\n",
      "172 \t\t 0.010394\n",
      "173 \t\t 0.010228\n",
      "174 \t\t 0.010064\n",
      "175 \t\t 0.009904\n",
      "176 \t\t 0.009745\n",
      "177 \t\t 0.009590\n",
      "178 \t\t 0.009437\n",
      "179 \t\t 0.009286\n",
      "180 \t\t 0.009138\n",
      "181 \t\t 0.008993\n",
      "182 \t\t 0.008850\n",
      "183 \t\t 0.008709\n",
      "184 \t\t 0.008570\n",
      "185 \t\t 0.008434\n",
      "186 \t\t 0.008299\n",
      "187 \t\t 0.008167\n",
      "188 \t\t 0.008037\n",
      "189 \t\t 0.007909\n",
      "190 \t\t 0.007783\n",
      "191 \t\t 0.007659\n",
      "192 \t\t 0.007537\n",
      "193 \t\t 0.007417\n",
      "194 \t\t 0.007299\n",
      "195 \t\t 0.007183\n",
      "196 \t\t 0.007068\n",
      "197 \t\t 0.006955\n",
      "198 \t\t 0.006845\n",
      "199 \t\t 0.006735\n",
      "200 \t\t 0.006628\n",
      "201 \t\t 0.006522\n",
      "202 \t\t 0.006418\n",
      "203 \t\t 0.006315\n",
      "204 \t\t 0.006214\n",
      "205 \t\t 0.006115\n",
      "206 \t\t 0.006017\n",
      "207 \t\t 0.005921\n",
      "208 \t\t 0.005826\n",
      "209 \t\t 0.005733\n",
      "210 \t\t 0.005641\n",
      "211 \t\t 0.005551\n",
      "212 \t\t 0.005462\n",
      "213 \t\t 0.005374\n",
      "214 \t\t 0.005288\n",
      "215 \t\t 0.005203\n",
      "216 \t\t 0.005120\n",
      "217 \t\t 0.005038\n",
      "218 \t\t 0.004957\n",
      "219 \t\t 0.004877\n",
      "220 \t\t 0.004799\n",
      "221 \t\t 0.004721\n",
      "222 \t\t 0.004645\n",
      "223 \t\t 0.004571\n",
      "224 \t\t 0.004497\n",
      "225 \t\t 0.004425\n",
      "226 \t\t 0.004353\n",
      "227 \t\t 0.004283\n",
      "228 \t\t 0.004214\n",
      "229 \t\t 0.004146\n",
      "230 \t\t 0.004079\n",
      "231 \t\t 0.004014\n",
      "232 \t\t 0.003949\n",
      "233 \t\t 0.003885\n",
      "234 \t\t 0.003822\n",
      "235 \t\t 0.003761\n",
      "236 \t\t 0.003700\n",
      "237 \t\t 0.003640\n",
      "238 \t\t 0.003581\n",
      "239 \t\t 0.003523\n",
      "240 \t\t 0.003466\n",
      "241 \t\t 0.003410\n",
      "242 \t\t 0.003355\n",
      "243 \t\t 0.003301\n",
      "244 \t\t 0.003247\n",
      "245 \t\t 0.003195\n",
      "246 \t\t 0.003143\n",
      "247 \t\t 0.003092\n",
      "248 \t\t 0.003042\n",
      "249 \t\t 0.002993\n",
      "250 \t\t 0.002944\n",
      "251 \t\t 0.002896\n",
      "252 \t\t 0.002849\n",
      "253 \t\t 0.002803\n",
      "254 \t\t 0.002758\n",
      "255 \t\t 0.002713\n",
      "256 \t\t 0.002669\n",
      "257 \t\t 0.002626\n",
      "258 \t\t 0.002583\n",
      "259 \t\t 0.002541\n",
      "260 \t\t 0.002500\n",
      "261 \t\t 0.002459\n",
      "262 \t\t 0.002419\n",
      "263 \t\t 0.002380\n",
      "264 \t\t 0.002341\n",
      "265 \t\t 0.002303\n",
      "266 \t\t 0.002266\n",
      "267 \t\t 0.002229\n",
      "268 \t\t 0.002193\n",
      "269 \t\t 0.002157\n",
      "270 \t\t 0.002122\n",
      "271 \t\t 0.002088\n",
      "272 \t\t 0.002054\n",
      "273 \t\t 0.002021\n",
      "274 \t\t 0.001988\n",
      "275 \t\t 0.001955\n",
      "276 \t\t 0.001924\n",
      "277 \t\t 0.001892\n",
      "278 \t\t 0.001862\n",
      "279 \t\t 0.001831\n",
      "280 \t\t 0.001802\n",
      "281 \t\t 0.001772\n",
      "282 \t\t 0.001744\n",
      "283 \t\t 0.001715\n",
      "284 \t\t 0.001687\n",
      "285 \t\t 0.001660\n",
      "286 \t\t 0.001633\n",
      "287 \t\t 0.001606\n",
      "288 \t\t 0.001580\n",
      "289 \t\t 0.001555\n",
      "290 \t\t 0.001529\n",
      "291 \t\t 0.001505\n",
      "292 \t\t 0.001480\n",
      "293 \t\t 0.001456\n",
      "294 \t\t 0.001432\n",
      "295 \t\t 0.001409\n",
      "296 \t\t 0.001386\n",
      "297 \t\t 0.001364\n",
      "298 \t\t 0.001342\n",
      "299 \t\t 0.001320\n",
      "300 \t\t 0.001298\n",
      "301 \t\t 0.001277\n",
      "302 \t\t 0.001257\n",
      "303 \t\t 0.001236\n",
      "304 \t\t 0.001216\n",
      "305 \t\t 0.001196\n",
      "306 \t\t 0.001177\n",
      "307 \t\t 0.001158\n",
      "308 \t\t 0.001139\n",
      "309 \t\t 0.001121\n",
      "310 \t\t 0.001102\n",
      "311 \t\t 0.001085\n",
      "312 \t\t 0.001067\n",
      "313 \t\t 0.001050\n",
      "314 \t\t 0.001033\n",
      "315 \t\t 0.001016\n",
      "316 \t\t 0.000999\n",
      "317 \t\t 0.000983\n",
      "318 \t\t 0.000967\n",
      "319 \t\t 0.000952\n",
      "320 \t\t 0.000936\n",
      "321 \t\t 0.000921\n",
      "322 \t\t 0.000906\n",
      "323 \t\t 0.000891\n",
      "324 \t\t 0.000877\n",
      "325 \t\t 0.000863\n",
      "326 \t\t 0.000849\n",
      "327 \t\t 0.000835\n",
      "328 \t\t 0.000821\n",
      "329 \t\t 0.000808\n",
      "330 \t\t 0.000795\n",
      "331 \t\t 0.000782\n",
      "332 \t\t 0.000769\n",
      "333 \t\t 0.000757\n",
      "334 \t\t 0.000745\n",
      "335 \t\t 0.000733\n",
      "336 \t\t 0.000721\n",
      "337 \t\t 0.000709\n",
      "338 \t\t 0.000698\n",
      "339 \t\t 0.000686\n",
      "340 \t\t 0.000675\n",
      "341 \t\t 0.000664\n",
      "342 \t\t 0.000654\n",
      "343 \t\t 0.000643\n",
      "344 \t\t 0.000633\n",
      "345 \t\t 0.000622\n",
      "346 \t\t 0.000612\n",
      "347 \t\t 0.000602\n",
      "348 \t\t 0.000593\n",
      "349 \t\t 0.000583\n",
      "350 \t\t 0.000574\n",
      "351 \t\t 0.000564\n",
      "352 \t\t 0.000555\n",
      "353 \t\t 0.000546\n",
      "354 \t\t 0.000537\n",
      "355 \t\t 0.000529\n",
      "356 \t\t 0.000520\n",
      "357 \t\t 0.000512\n",
      "358 \t\t 0.000504\n",
      "359 \t\t 0.000495\n",
      "360 \t\t 0.000487\n",
      "361 \t\t 0.000480\n",
      "362 \t\t 0.000472\n",
      "363 \t\t 0.000464\n",
      "364 \t\t 0.000457\n",
      "365 \t\t 0.000449\n",
      "366 \t\t 0.000442\n",
      "367 \t\t 0.000435\n",
      "368 \t\t 0.000428\n",
      "369 \t\t 0.000421\n",
      "370 \t\t 0.000414\n",
      "371 \t\t 0.000408\n",
      "372 \t\t 0.000401\n",
      "373 \t\t 0.000395\n",
      "374 \t\t 0.000388\n",
      "375 \t\t 0.000382\n",
      "376 \t\t 0.000376\n",
      "377 \t\t 0.000370\n",
      "378 \t\t 0.000364\n",
      "379 \t\t 0.000358\n",
      "380 \t\t 0.000352\n",
      "381 \t\t 0.000346\n",
      "382 \t\t 0.000341\n",
      "383 \t\t 0.000335\n",
      "384 \t\t 0.000330\n",
      "385 \t\t 0.000325\n",
      "386 \t\t 0.000319\n",
      "387 \t\t 0.000314\n",
      "388 \t\t 0.000309\n",
      "389 \t\t 0.000304\n",
      "390 \t\t 0.000299\n",
      "391 \t\t 0.000294\n",
      "392 \t\t 0.000290\n",
      "393 \t\t 0.000285\n",
      "394 \t\t 0.000280\n",
      "395 \t\t 0.000276\n",
      "396 \t\t 0.000272\n",
      "397 \t\t 0.000267\n",
      "398 \t\t 0.000263\n",
      "399 \t\t 0.000259\n",
      "400 \t\t 0.000254\n",
      "401 \t\t 0.000250\n",
      "402 \t\t 0.000246\n",
      "403 \t\t 0.000242\n",
      "404 \t\t 0.000238\n",
      "405 \t\t 0.000235\n",
      "406 \t\t 0.000231\n",
      "407 \t\t 0.000227\n",
      "408 \t\t 0.000223\n",
      "409 \t\t 0.000220\n",
      "410 \t\t 0.000216\n",
      "411 \t\t 0.000213\n",
      "412 \t\t 0.000209\n",
      "413 \t\t 0.000206\n",
      "414 \t\t 0.000203\n",
      "415 \t\t 0.000200\n",
      "416 \t\t 0.000196\n",
      "417 \t\t 0.000193\n",
      "418 \t\t 0.000190\n",
      "419 \t\t 0.000187\n",
      "420 \t\t 0.000184\n",
      "421 \t\t 0.000181\n",
      "422 \t\t 0.000178\n",
      "423 \t\t 0.000175\n",
      "424 \t\t 0.000172\n",
      "425 \t\t 0.000170\n",
      "426 \t\t 0.000167\n",
      "427 \t\t 0.000164\n",
      "428 \t\t 0.000162\n",
      "429 \t\t 0.000159\n",
      "430 \t\t 0.000156\n",
      "431 \t\t 0.000154\n",
      "432 \t\t 0.000151\n",
      "433 \t\t 0.000149\n",
      "434 \t\t 0.000147\n",
      "435 \t\t 0.000144\n",
      "436 \t\t 0.000142\n",
      "437 \t\t 0.000140\n",
      "438 \t\t 0.000137\n",
      "439 \t\t 0.000135\n",
      "440 \t\t 0.000133\n",
      "441 \t\t 0.000131\n",
      "442 \t\t 0.000129\n",
      "443 \t\t 0.000127\n",
      "444 \t\t 0.000125\n",
      "445 \t\t 0.000123\n",
      "446 \t\t 0.000121\n",
      "447 \t\t 0.000119\n",
      "448 \t\t 0.000117\n",
      "449 \t\t 0.000115\n",
      "450 \t\t 0.000113\n"
     ]
    }
   ],
   "source": [
    "# run SVD on the matrix with the missing value\n",
    "user_mat, movie_mat = FunkSVD(ratings_mat, \n",
    "                              latent_features=3, \n",
    "                              learning_rate=0.005, \n",
    "                              iters=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted value for the missing rating is: 2.177346902360894\n"
     ]
    }
   ],
   "source": [
    "preds = np.dot(user_mat, movie_mat)\n",
    "print(\"The predicted value for the missing rating is: {}\".format(preds[0,0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extend this to a more realistic example. Unfortunately, running this function on your entire user-movie matrix is still not something you likely want to do on your local machine. However, we can see how well this example extends to 1000 users. In the above portion, you were using a very small subset of data with no missing values.\n",
    "\n",
    "5. Given the size of this matrix, this will take quite a bit of time. Consider the following hyperparameters: 3 latent features, 0.005 learning rate, and 500 iterations. Grab a snack, take a walk, and this should be done running in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a matrix of the first 1000 users with movie ratings\n",
    "first_1000_users = np.matrix(movie_pivot.head(1000))\n",
    "first_1000_users[first_1000_users == 0] = np.nan\n",
    "\n",
    "# # perform funkSVD on the matrix of the top 1000 users\n",
    "# user_mat, movie_mat = FunkSVD(first_1000_users, \n",
    "#                               latent_features=3, \n",
    "#                               learning_rate=0.005, \n",
    "#                               iters=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the famous SVD algorithm.\n",
    "svd = SVD()\n",
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(final_rating[['userId', 'title', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ratings_small dataset (download it if needed),\n",
    "# data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7394  0.7395  0.7391  0.7401  0.7399  0.7396  0.0004  \n",
      "MAE (testset)     0.5604  0.5606  0.5602  0.5607  0.5606  0.5605  0.0002  \n",
      "Fit time          215.55  219.23  215.89  218.94  217.25  217.37  1.51    \n",
      "Test time         59.05   49.73   44.20   60.62   40.59   50.84   7.92    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.73940993, 0.73953583, 0.73905324, 0.74005728, 0.73988416]),\n",
       " 'test_mae': array([0.56038511, 0.5606157 , 0.56015645, 0.5607372 , 0.56057395]),\n",
       " 'fit_time': (215.55395007133484,\n",
       "  219.2347650527954,\n",
       "  215.89060854911804,\n",
       "  218.93954825401306,\n",
       "  217.250962972641),\n",
       " 'test_time': (59.054768085479736,\n",
       "  49.72729754447937,\n",
       "  44.19604015350342,\n",
       "  60.61952543258667,\n",
       "  40.588096618652344)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample full trainset\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1a5ae3d4f70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the algorithm on the trainset\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userId, movieId, rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df[ratings_df['userId'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=302, r_ui=None, est=3.437940601992745, details={'was_impossible': False})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict ratings for the testset\n",
    "svd.predict(uid=1, iid=302, r_ui=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.437940601992745"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly grab the estimated ratings for the testset\n",
    "svd.predict(uid=1, iid=302, r_ui=None).est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6588103254769924"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df[ratings_df['movieId'] == 302].rating.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=100, iid=302, r_ui=None, est=3.9398385352737106, details={'was_impossible': False})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict ratings for the testset\n",
    "svd.predict(uid=100, iid=302, r_ui=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9398385352737106"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly grab the estimated ratings for the testset\n",
    "svd.predict(uid=100, iid=302, r_ui=None).est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "U shape: torch.Size([943, 943])\n",
      "S shape: torch.Size([943])\n",
      "V shape: torch.Size([1682, 943])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from surprise import Dataset\n",
    "from surprise import SVD, Reader\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "reader = Reader()\n",
    "# Load the Surprise dataset\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "# data = Dataset.load_from_df(final_rating[['userId', 'title', 'rating']], reader)\n",
    "# Build the trainset\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Get the ratings data\n",
    "ratings_data = list(trainset.all_ratings())\n",
    "\n",
    "if len(ratings_data) == 0:\n",
    "    # Handle the case when there is no rating data\n",
    "    print(\"No rating data available.\")\n",
    "else:\n",
    "    # Extract user IDs, item IDs, and ratings from the ratings data\n",
    "    user_ids = [r[0] for r in ratings_data]\n",
    "    item_ids = [r[1] for r in ratings_data]\n",
    "    ratings = [r[2] for r in ratings_data]\n",
    "\n",
    "    # Create a sparse ratings matrix\n",
    "    ratings_matrix = csr_matrix((ratings, (user_ids, item_ids)))\n",
    "\n",
    "    # Convert the sparse matrix to a PyTorch tensor\n",
    "    ratings_tensor = torch.FloatTensor(ratings_matrix.toarray())\n",
    "\n",
    "    # Move the ratings tensor to the GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ratings_tensor = ratings_tensor.to(device)\n",
    "    # Print if using CPU or GPU\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Perform SVD on GPU\n",
    "    U, S, V = torch.svd(ratings_tensor)\n",
    "\n",
    "    # Move the resulting matrices back to the CPU if needed\n",
    "    U = U.cpu()\n",
    "    S = S.cpu()\n",
    "    V = V.cpu()\n",
    "\n",
    "    # Print the shapes of U, S, V\n",
    "    print('U shape:', U.shape)\n",
    "    print('S shape:', S.shape)\n",
    "    print('V shape:', V.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
